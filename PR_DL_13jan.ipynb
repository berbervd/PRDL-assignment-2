{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ea75b3-37ad-4e99-99d2-04178c491366",
   "metadata": {},
   "source": [
    "# Lezen van de files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6afa23-2777-430c-a3fb-536fb9a170c7",
   "metadata": {},
   "source": [
    "Importeren libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db3a75c-8195-40f9-a596-12a6a7f6fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151047a-87c1-4aa6-89f6-317a50691c3f",
   "metadata": {},
   "source": [
    "Hier 1 class van maken, doet:\n",
    "* lezen van de data\n",
    "* Specificeren van de folder waarvan je de data wil inlezen in folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcde49-0ad3-4abb-a708-7c4e91c899a9",
   "metadata": {},
   "source": [
    "## Class voor all preprocess stappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412fbb08-7ad0-4718-83c9-d15e04080d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, base_directory=''):\n",
    "        self.base_directory = base_directory\n",
    "\n",
    "    def get_dataset_name(self, file_name_with_dir):\n",
    "        filename_without_dir = file_name_with_dir.split('/')[-1]\n",
    "        temp = filename_without_dir.split('_')[:-1]\n",
    "        dataset_name = \"_\".join(temp)\n",
    "        return dataset_name\n",
    "\n",
    "    def znorm(self, data):\n",
    "        \"\"\"\n",
    "        Normalizes time-wise\n",
    "        \"\"\"\n",
    "        mean_rows = np.mean(data, axis=1, keepdims=True)\n",
    "        std_rows = np.std(data, axis=1, keepdims=True)\n",
    "        scaled_data = ((data - mean_rows) / std_rows)\n",
    "        return scaled_data\n",
    "\n",
    "    def load_data_from_folder(self, folder, shuffle=True, downsample_factor=4):\n",
    "        data_directory = os.path.join(self.base_directory, folder)\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        label_mapping = {\n",
    "            'rest': 0,\n",
    "            'task_motor': 1,\n",
    "            'task_story_math': 2,\n",
    "            'task_working_memory': 3\n",
    "        }\n",
    "\n",
    "        file_names = [file_name for file_name in os.listdir(data_directory) if file_name.endswith(\".h5\")]\n",
    "        if shuffle:\n",
    "            random.shuffle(file_names)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(data_directory, file_name)\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                dataset_name = self.get_dataset_name(file_name)\n",
    "                matrix = f.get(dataset_name)[()]\n",
    "\n",
    "                label = None\n",
    "                for task_prefix in label_mapping.keys():\n",
    "                    if task_prefix in file_name:\n",
    "                        label = label_mapping[task_prefix]  # Use the numerical value from label_mapping\n",
    "                        break\n",
    "\n",
    "                if label is not None:\n",
    "                    matrix = self.znorm(matrix)\n",
    "                    matrix = matrix[:, ::downsample_factor]\n",
    "\n",
    "                    data.append(matrix)\n",
    "                    labels.append(label)  # Append the label directly\n",
    "                else:\n",
    "                    print(f\"Warning: No label found for file {file_name}\")\n",
    "\n",
    "        return np.array(data), np.array(labels)\n",
    "\n",
    "# Example usage\n",
    "data_loader = DataLoader()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ad1c1-69b1-43c1-9130-06d383e1ab01",
   "metadata": {},
   "source": [
    "### Inlezen Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761a905b-61bf-46b8-9716-b189d6abbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (64, 248, 8906), Train Labels Shape: (64,)\n",
      "Test1 Data Shape: (16, 248, 8906), Test1 Labels Shape: (16,)\n",
      "Test2 Data Shape: (16, 248, 8906), Test2 Labels Shape: (16,)\n",
      "Test3 Data Shape: (16, 248, 8906), Test3 Labels Shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "# CROSS\n",
    "\n",
    "# Load data and labels for each subset\n",
    "data_train1, labels_train1 = data_loader.load_data_from_folder('./Final Project data/Cross/train')\n",
    "data_test1, labels_test1 = data_loader.load_data_from_folder('./Final Project data/Cross/test1')\n",
    "data_test2, labels_test2 = data_loader.load_data_from_folder('./Final Project data/Cross/test2')\n",
    "data_test3, labels_test3 = data_loader.load_data_from_folder('./Final Project data/Cross/test3')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Train Data Shape: {data_train1.shape}, Train Labels Shape: {labels_train1.shape}\")\n",
    "print(f\"Test1 Data Shape: {data_test1.shape}, Test1 Labels Shape: {labels_test1.shape}\")\n",
    "print(f\"Test2 Data Shape: {data_test2.shape}, Test2 Labels Shape: {labels_test2.shape}\")\n",
    "print(f\"Test3 Data Shape: {data_test3.shape}, Test3 Labels Shape: {labels_test3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4488d-3c04-4ac9-8ad5-1770f8f6cf1d",
   "metadata": {},
   "source": [
    "### Inlezen Intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f838b5a9-39ae-4ad7-a68c-8c338ab2f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (32, 248, 8906)\n",
      "Labels Shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "# intra train\n",
    "\n",
    "# Load the preprocessed data and labels\n",
    "data_train, labels_train = data_loader.load_data_from_folder('./Final Project data/Intra/train')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Data Shape: {data_train.shape}\")\n",
    "print(f\"Labels Shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56520b47-d362-4080-ad8d-3d1caf8d2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (8, 248, 8906)\n",
      "Labels Shape: (8,)\n"
     ]
    }
   ],
   "source": [
    "## Test intra\n",
    "# Load the preprocessed data and labels\n",
    "data_test, labels_test = data_loader.load_data_from_folder('./Final Project data/Intra/test')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Data Shape: {data_test.shape}\")\n",
    "print(f\"Labels Shape: {labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d081997-15fd-4f3b-8ab6-e298629299aa",
   "metadata": {},
   "source": [
    "### Trainen + Maken van het model (intra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ded5ec6-c0d1-4fc6-a44c-d719004823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapen zodat het in de vorm: [nr samples, time steps, features] is, voor LSTM\n",
    "X_train = data_train1\n",
    "X_test = data_test1\n",
    "y_train = labels_train1\n",
    "y_test = labels_test1\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[2], X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eadb6ed-0d22-4cf8-ba2e-9f388dc43810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/geekculture/10-hyperparameters-to-keep-an-eye-on-for-your-lstm-model-and-other-tips-f0ff5b63fcd4\n",
    "# \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_model_oud(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=input_shape))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020780b",
   "metadata": {},
   "source": [
    "### LSTM met hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba38762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 14s]\n",
      "val_accuracy: 0.3125\n",
      "\n",
      "Best val_accuracy So Far: 0.3125\n",
      "Total elapsed time: 00h 00m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of LSTM and Dense layers and their units can be reviewed in the best hyperparameters.\n",
      "\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.8133 - accuracy: 0.2031 - val_loss: 2.8149 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ecb74fd00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tuning the number of LSTM layers and their units\n",
    "    for i in range(hp.Int('num_lstm_layers', 1, 2)):\n",
    "        model.add(LSTM(\n",
    "            units=hp.Choice('units_' + str(i), values=[16]), #values=[16, 32, 64, 128]\n",
    "            return_sequences=i < hp.get('num_lstm_layers') - 1,  # Only the last layer should not return sequences\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]) if i == 0 else None))\n",
    "\n",
    "    # Tuning the number of Dense layers and their units\n",
    "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Choice('dense_units_' + str(i), values=[16]), #values=[16, 32, 64, 128]\n",
    "            activation='relu'))\n",
    "\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', values=[1e-2])), #values=[1e-2, 1e-3, 1e-4]\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=1, #5\n",
    "    executions_per_trial=1, #3\n",
    "    directory='./',\n",
    "    project_name='hparam_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Start the hyperparameter tuning\n",
    "tuner.search(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of LSTM and Dense layers and their units can be reviewed in the best hyperparameters.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae53766-6fad-421f-8429-ead3772f1d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model((X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model((X_train.shape[1], X_train.shape[2]))\n",
    "history = model.fit(X_train, y_train, epochs=7, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cccfe8b-28c5-471e-96f4-2a578484fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step - loss: 2.8149 - accuracy: 0.3125\n",
      "Test Accuracy: 31.25%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb7c6a5b-baff-429a-883f-c0a2b275773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ae7df8-0251-4661-a85e-88de8b519123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 911ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1.6780759269094447\n"
     ]
    }
   ],
   "source": [
    "# predict:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "\n",
    "#rmse \n",
    "#trainScore = np.sqrt(mean_squared_error(y_train[0], trainPredict[:,0]))\n",
    "#print(trainScore)\n",
    "testScore = np.sqrt(mean_squared_error(y_test, testPredict[:,0]))\n",
    "print(testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dd7e3-156e-4221-9c88-22108da01cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
