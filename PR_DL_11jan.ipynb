{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ea75b3-37ad-4e99-99d2-04178c491366",
   "metadata": {},
   "source": [
    "# Lezen van de files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6afa23-2777-430c-a3fb-536fb9a170c7",
   "metadata": {},
   "source": [
    "Importeren libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db3a75c-8195-40f9-a596-12a6a7f6fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151047a-87c1-4aa6-89f6-317a50691c3f",
   "metadata": {},
   "source": [
    "Hier 1 class van maken, doet:\n",
    "* lezen van de data\n",
    "* Specificeren van de folder waarvan je de data wil inlezen in folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcde49-0ad3-4abb-a708-7c4e91c899a9",
   "metadata": {},
   "source": [
    "## Class voor all preprocess stappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "412fbb08-7ad0-4718-83c9-d15e04080d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deze class zorgt ervoor dat de data wordt geladen , de folder moet gespecificeerd worden bij het aanroepen. \n",
    "Het geeft een matrix terug met sensors als rows en timestamps als columns, en de labels (de tasks)\n",
    "\"\"\"\n",
    "class DataLoader:\n",
    "    def __init__(self, base_directory='Final_Project_data/'):\n",
    "        self.base_directory = base_directory\n",
    "\n",
    "    def get_dataset_name(self, file_name_with_dir):\n",
    "        filename_without_dir = file_name_with_dir.split('/')[-1]\n",
    "        temp = filename_without_dir.split('_')[:-1]\n",
    "        dataset_name = \"_\".join(temp)\n",
    "        return dataset_name\n",
    "\n",
    "    def znorm(self, data):\n",
    "        \"\"\"\n",
    "        Normalizes time-wise\n",
    "        \"\"\"\n",
    "        mean_rows = np.mean(data, axis=1, keepdims=True)\n",
    "        std_rows = np.std(data, axis=1, keepdims=True)\n",
    "        scaled_data = ((data - mean_rows) / std_rows)\n",
    "        return scaled_data\n",
    "\n",
    "    def load_data_from_folder(self, folder, shuffle=True, downsample_factor=4): # hier kan de downsampling factor veranderd worden\n",
    "        data_directory = os.path.join(self.base_directory, folder)\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        label_mapping = {\n",
    "            'rest': 0,\n",
    "            'task_motor': 1,\n",
    "            'task_story_math': 2,\n",
    "            'task_working_memory': 3\n",
    "        }\n",
    "\n",
    "        file_names = [file_name for file_name in os.listdir(data_directory) if file_name.endswith(\".h5\")]\n",
    "        if shuffle:\n",
    "            random.shuffle(file_names)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(data_directory, file_name)\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                dataset_name = self.get_dataset_name(file_name)\n",
    "                matrix = f.get(dataset_name)[()]\n",
    "\n",
    "                label = None\n",
    "                for task_prefix in label_mapping.keys():\n",
    "                    if task_prefix in file_name:\n",
    "                        label = task_prefix\n",
    "                        break\n",
    "\n",
    "                if label is not None:\n",
    "                    matrix = self.znorm(matrix)\n",
    "                    matrix = matrix[:, ::downsample_factor]\n",
    "\n",
    "                    one_hot_label = np.zeros(len(label_mapping))\n",
    "                    one_hot_label[label_mapping[label]] = 1\n",
    "                    data.append(matrix)\n",
    "                    labels.append(one_hot_label)\n",
    "                else:\n",
    "                    print(f\"Warning: No label found for file {file_name}\")\n",
    "\n",
    "        return np.array(data), np.array(labels)\n",
    "        \n",
    "data_loader = DataLoader()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ad1c1-69b1-43c1-9130-06d383e1ab01",
   "metadata": {},
   "source": [
    "### Inlezen Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "761a905b-61bf-46b8-9716-b189d6abbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (64, 248, 8906), Train Labels Shape: (64, 4)\n",
      "Test1 Data Shape: (16, 248, 8906), Test1 Labels Shape: (16, 4)\n",
      "Test2 Data Shape: (16, 248, 8906), Test2 Labels Shape: (16, 4)\n",
      "Test3 Data Shape: (16, 248, 8906), Test3 Labels Shape: (16, 4)\n"
     ]
    }
   ],
   "source": [
    "# CROSS\n",
    "\n",
    "# Load data and labels for each subset\n",
    "data_train, labels_train = data_loader.load_data_from_folder('Cross/train')\n",
    "data_test1, labels_test1 = data_loader.load_data_from_folder('Cross/test1')\n",
    "data_test2, labels_test2 = data_loader.load_data_from_folder('Cross/test2')\n",
    "data_test3, labels_test3 = data_loader.load_data_from_folder('Cross/test3')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Train Data Shape: {data_train.shape}, Train Labels Shape: {labels_train.shape}\")\n",
    "print(f\"Test1 Data Shape: {data_test1.shape}, Test1 Labels Shape: {labels_test1.shape}\")\n",
    "print(f\"Test2 Data Shape: {data_test2.shape}, Test2 Labels Shape: {labels_test2.shape}\")\n",
    "print(f\"Test3 Data Shape: {data_test3.shape}, Test3 Labels Shape: {labels_test3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4488d-3c04-4ac9-8ad5-1770f8f6cf1d",
   "metadata": {},
   "source": [
    "### Inlezen Intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f838b5a9-39ae-4ad7-a68c-8c338ab2f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (32, 248, 8906)\n",
      "Labels Shape: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "# intra train\n",
    "\n",
    "# Load the preprocessed data and labels\n",
    "data_train, labels_train = data_loader.load_data_from_folder('Intra/train')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Data Shape: {data_train.shape}\")\n",
    "print(f\"Labels Shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56520b47-d362-4080-ad8d-3d1caf8d2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (8, 248, 8906)\n",
      "Labels Shape: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "## Test intra\n",
    "# Load the preprocessed data and labels\n",
    "data_test, labels_test = data_loader.load_data_from_folder('Intra/test')\n",
    "\n",
    "# Print shapes of loaded data\n",
    "print(f\"Data Shape: {data_test.shape}\")\n",
    "print(f\"Labels Shape: {labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d081997-15fd-4f3b-8ab6-e298629299aa",
   "metadata": {},
   "source": [
    "### Trainen + Maken van het model (intra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ded5ec6-c0d1-4fc6-a44c-d719004823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapen zodat het in de vorm: [nr samples, time steps, features] is, voor LSTM\n",
    "X_train = data_train\n",
    "X_test = data_test\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[2], X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eadb6ed-0d22-4cf8-ba2e-9f388dc43810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a4a9d8a-461f-4a0d-bfcf-cdcf1a6ae833",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labels_train\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ae53766-6fad-421f-8429-ead3772f1d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6337 - accuracy: 0.1875 - val_loss: 1.5367 - val_accuracy: 0.2500\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.4427 - accuracy: 0.3750 - val_loss: 1.4541 - val_accuracy: 0.2500\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.3158 - accuracy: 0.3438 - val_loss: 1.3396 - val_accuracy: 0.3750\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.2717 - accuracy: 0.2812 - val_loss: 1.3728 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "model = create_model((X_train.shape[1], X_train.shape[2]))\n",
    "history = model.fit(X_train, y_train, epochs=4, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cccfe8b-28c5-471e-96f4-2a578484fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 307ms/step - loss: 1.3728 - accuracy: 0.3750\n",
      "Test Accuracy: 37.50%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
